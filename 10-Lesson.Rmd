# Tuesday, September 27, 2022 {-}

Today

- More on making maps
- Calculations using the geometry simple feature column 
- Making raster maps

## Making maps using functions from the {tmap} package {-}

The {tmap} package has functions for creating thematic maps. The syntax is like the syntax of the functions in {ggplot2}. The functions work with a variety of spatial data.

Consider the simple feature data frame called `World` from the {tmap} package.
```{r}
library(tmap)

data("World")
str(World)
```

The spatial data frame contains socioeconomic indicators from 177 countries around the world. Each row is one country's indicators.

You make a map by first specifying the spatial data frame using the `tm_shape()` function and then you add a layer consistent with the geometry.

For example, if you want a map showing the index of happiness (column name `HPI`) by country, use the `tm_shape()` function to identify the spatial data frame `World` then add a fill layer with the `tm_polygons()` function. 

The fill is specified by the argument `col =` indicating the specific column from the data frame. Here use `HPI`.
```{r}
tm_shape(shp = World) +
    tm_polygons(col = "HPI")
```

The `tm_polygons()` function with the argument `col =` colors the countries based on the values in the column `HPI` of the `World` data frame. 

Map layers are added with the `+` operator.

Caution: the column in the data frame `World` must be specified using quotes `"HPI"`. This is different from the functions in the {ggplot2} package.

To show two thematic maps together each with a different variable, specify `col = c("HPI", "well_being")`

The `tm_polygons()` function splits the values in the specified column into meaningful groups (here 8) and countries with missing values (`NA`) values are colored gray. 

More (or fewer) intervals can be specified with the `n = ` argument, but the cutoff values are chosen at appropriate places.

Example: Mapping tornadoes

Consider the tornado data from the U.S. Storm Prediction Center (SPC). It is downloaded as a shapefile in the directory `data/1950-2018-torn-aspath`.

A shapefile is imported with the `sf::st_read()` function from the {sf} package.
```{r}
Tornadoes.sf <- sf::st_read(dsn = "data/1950-2018-torn-aspath")
```

The assigned file is a simple feature data frame with 63645 features (observations) and 23 fields (variables). 

Each row (observation) is a unique tornado.

Look inside the simple feature data frame with the `glimpse()` function from the {dplyr} package.
```{r}
dplyr::glimpse(Tornadoes.sf)
```

The first 22 columns are variables (attributes). The last column contains the geometry. Information in the `geometry` column is in well-known text (WKT) format. 

Each tornado is a coded as a `LINESTRING` with a start and end location. This is where the `tm_shape()` function looks for the geographic information.

Here you make a map showing the tracks of all the tornadoes since 2011. First filter the data frame keeping only tornadoes occurring after the year (`yr`) 2010.
```{r}
TornadoesSince2011.sf <- 
  Tornadoes.sf |>
  dplyr::filter(yr >= 2011) 
```

Next get a file containing the boundaries of the lower 48 states.
```{r}
USA_48.sf <- USAboundaries::us_states() |>
   dplyr::filter(!state_name %in% c("Hawaii", "Alaska", "Puerto Rico"))
```

Then use the `tm_shape()` function together with the `tm_borders()` layer to draw the boundaries before adding the tornadoes. The tornadoes are in a separate spatial data frame so you use the `tm_shape()` function together with the `tm_lines()` layer.
```{r}
tm_shape(shp = USA_48.sf, projection = 5070) +
  tm_borders() +
tm_shape(shp = TornadoesSince2011.sf) +
    tm_lines(col = "red")
```

The objects named `TornadoesSince2011.sf` and `USA_48.sf` are simple feature data frames. You map variables in the data frames as layers with successive calls to the `tm_shape()` function.

The default projection is geographic (latitude-longitude) which is changed using the `projection =` argument and specifying a EPSG number (or proj4 string). Here you use 5070 corresponding to USA Contiguous Albers Equal Area Conic, USGS (EPSG = 5070 or 102003).

You make the map interactive by first turning on the `"view"` mode with the `tmap_mode()` function before running the code. 
```{r}
tmap_mode("view")

tm_shape(USA_48.sf) +
  tm_borders() +
tm_shape(TornadoesSince2011.sf) +
    tm_lines(col = "red")
```

You can now zoom, pan, and change the background layers.

Switch back to plot mode by typing.
```{r}
tmap_mode("plot")
```

Example: Mapping the frequency of tornadoes by state

Suppose you want to show the number of tornadoes originating in each state on a map. You first need to prepare the data.

You do this with a series of `then` statements connected by pipes (`|>`). Start by assigning to the object `TornadoeCountsByState.df` the contents of `Tornadoes.sf` then remove the the geometry column, then remove states outside lower 48 using the `dplyr::filter()` function, then group by state, then summarize creating a colunm called `nT` that keeps track of the number of rows (`dplyr::n()`), then change the column name of `st` to `state_abbr` to match the state name abbreviation in the `USA_48.sf` data frame.
```{r}
TornadoCountsByState.df <- Tornadoes.sf |>
  sf::st_drop_geometry() |>
  dplyr::filter(st != "PR" & st != "HI" & st != "AK") |>
  dplyr::group_by(st) |>
  dplyr::summarize(nT = dplyr::n()) |>
  dplyr::rename(state_abbr = st)

dplyr::glimpse(TornadoCountsByState.df)
```

The resulting data frame contains the grouped-by column `state_abbr` (origin state) and the corresponding number of tornadoes. There were 459 tornadoes in Alabama since 2011, 255 in Arkansas, etc.

Next you need to join the new data frame with the spatial data frame. You join the `TornadoCountsByState.df` data frame with the map simple feature data frame `USA_48.sf` using the `dplyr::left_join()` function and recycling the name.
```{r}
USA_48.sf <-dplyr::left_join(USA_48.sf,
                             TornadoCountsByState.df,
                             by = "state_abbr") 

names(USA_48.sf)
```

Notice that you now have a new column in the spatial data frame `USA_48.sf` named `nT` that contains the number of tornadoes in that state.

Next you create a draft map to see if things look correct.
```{r}
tm_shape(shp = USA_48.sf, projection = 5070) +
  tm_polygons(col = "nT", 
           title = "Tornado Counts",
           palette = "Oranges")
```
Tornadoes are most common in the southern Great Plains into the Southeast.

You improve the defaults with additional layers including text, compass, and scale bar. The last layer is the print view.
```{r}
tm_shape(shp = USA_48.sf, projection = 5070) +
  tm_polygons(col = "nT", 
              border.col = "gray70",
              title = "Tornado Counts",
              palette = "Oranges") +
  tm_text("nT", size = .5) +
  tm_compass() + 
  tm_scale_bar(lwd = .5)
```

The format of the {tmap} objects (meoms) are like those of the {ggplot2} geometric objects (geoms) making it easy to quickly map your data. Fine details are worked out in production.

[More information?](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html)

## Calculations using the geometry simple feature column {-}

Spatial data analysis often requires calculations on the geometry. Two of the most common are computing centroids (geographic centers) and buffers.

Geometry calculations should be done on projected coordinates. To see what CRS the simple feature data frame has use `st_crs()`.
```{r}
sf::st_crs(USA_48.sf)
```

Note the length unit (`LENGTHUNIT[]`) is meter.

Here transform the CRS of the `USA_48.sf` simple feature data frame to a U.S. National Atlas equal area (EPSG: 2163) and then check it.
```{r}
USA_48.sf <- USA_48.sf |>
  sf::st_transform(crs = 2163)

sf::st_crs(USA_48.sf)
```

The centroid calculation locates the center of geographic objects representing the center of mass for the spatial object (think of balancing a plate on your finger).

You calculate the geographic centroid of each of the lower 48 states with the `st_centroid()` function.
```{r}
geo_centroid.sf <- sf::st_centroid(USA_48.sf)
```

The result is a simple feature data frame where the geometry is a single point for each state. You keep track of the fact that this is a simple feature data frame by using an object name that includes appends with `.sf`.

The warning tells you that the attributes in the new simple feature data frame may not make sense with the new geometry.

For example, compare the first two rows of the two simple feature data frames.
```{r}
head(geo_centroid.sf, n = 2)
head(USA_48.sf, n = 2)
```

The land area (`aland`) makes sense when the geometry is `MULTIPOLYGON` it is less congruent when the geometry is `POINT`.

You map the points using the `tm_dots()` function after first mapping the state borders.
```{r}
tm_shape(shp = USA_48.sf) +
  tm_borders(col = "gray70") +
tm_shape(shp = geo_centroid.sf) +
  tm_dots(size = 1,
          col = "black")
```

Buffers are polygons representing the area within a given distance of a geometric feature. Regardless of whether the feature is a point, a line, or a polygon. 

The function `sf::st_buffer()` computes the buffer and you set the distance with the `dist = ` argument. Here you create a new simple feature data frame with only the state of Florida. 

You then compute a 50 km (50,000 meters) buffer and save the resulting polygon 
```{r}
FL.sf <- USA_48.sf |>
           dplyr::filter(state_abbr == "FL")

FL_buffer.sf <- sf::st_buffer(FL.sf, 
                              dist = 50000)
```

Create a map containing the state border, the 50 km buffer, and the centroid. Include a compass arrow and a scale bar.
```{r}
tm_shape(FL_buffer.sf) +
  tm_borders(col = "gray70") +
tm_shape(FL.sf) +
  tm_borders() +
tm_shape(geo_centroid.sf) +
  tm_dots(size = 2) +
tm_compass(position = c("left", "bottom")) + 
tm_scale_bar(text.size = 1, position = c("left", "bottom"))
```

The result is a map that could serve as a map of your study area (usually Figure 1 in scientific report).

## Making raster maps {-}

The package {ggmap} retrieves raster map tiles (groups of pixels) from services like Google Maps and plots them using the {ggplot2} grammar.

Map tiles are rasters as static image files generated by the mapping service. You do not need data files containing information on things like scale, projection, boundaries, etc. because that information is created by the map tile.

This limits the ability to redraw or change the appearance of the map but it allows for easy overlays of data onto the map.

Get map tiles using functions from the {ggmap} package

You get map tiles with the `ggmap::get_map()` function from the {ggmap} package. You specify the bounding box (or the center and zoom). The bounding box requires the left-bottom and right-top corners of the region specified as longitude and latitude in decimal degrees.

For instance, to obtain a map of Tallahassee from the stamen mapping service you first set the bounding box (left-bottom corner as -84.41, 30.37 and right-top corner as -84.19, 30.55) then use the `ggmap::get_stamenmap()` function with a zoom level of 12.
```{r, message=FALSE}
library(ggmap)

TLH_bb <- c(left = -84.41,
            bottom = 30.37,
            right = -84.19,
            top = 30.55)

TLH_map <- ggmap::get_stamenmap(bbox = TLH_bb,
                                zoom = 12)
TLH_map
```

The saved object (`TLH_map`) is a raster map specified by the class `ggmap`.

To view the map, use `ggmap()` function.
```{r}
ggmap(TLH_map)
```

The `zoom =` argument in the `get_stamenmap()` function controls the level of detail. The larger the number, the greater the detail.

Trial and error helps you decide on the appropriate level of detail depending on the data you need to visualize. Use [boxfinder](bboxfinder.com) to determine the exact longitude/latitude coordinates for the bounding box you wish to obtain.

Or you can use the `tmaptools::geocode_OSM()` function from the {tmaptools} package. You first specify a location then get a geocoded coordinate.
```{r}
FSU.list <- tmaptools::geocode_OSM("Florida State University")
FSU.list
```

The object `FSU.list` is a list containing three elements `query`, `coords` and `bbox`. You are interested in the `bbox` element so you save that as vector that you assign `FSU_bb` and rename the elements to left, bottom, right, and top.
```{r}
FSU_bb <- FSU.list$bbox
names(FSU_bb) <- c("left", "bottom", 
                   "right", "top")
FSU_bb
```

You then get the map tiles corresponding to the bounding box from the stamen map service with a zoom of 16 and create the map.
```{r, message=FALSE}
FSU_map <- ggmap::get_stamenmap(bbox = FSU_bb, 
                                zoom = 16)
ggmap(FSU_map)
```

Add data to the raster map

Let's consider a map of Chicago.
```{r, message=FALSE}
CHI_bb <- c(left = -87.936287,
            bottom = 41.679835,
            right = -87.447052,
            top = 42.000835)

CHI_map <- get_stamenmap(bbox = CHI_bb,
                         zoom = 11,
                         messaging = FALSE)
ggmap(CHI_map)
```

The city of Chicago has a data portal publishing a large volume of public records. Here you look at crime data from 2017. The file `car_thefts.csv` is a spreadsheet obtained from that portal with a list of car thefts. 

You read these data using the `readr::read_csv()` function.
```{r}
carTheft <- readr::read_csv(file = "data/car_thefts.csv")
head(carTheft)
```

Each row of the data frame is a single report of a vehicle theft. Location is encoded in several ways, though most importantly for us the longitude and latitude of the theft is encoded in the `Longitude` and `Latitude` columns, respectively.

You use the `geom_point()` function to map the location of every theft. Because `ggmap()` uses the map tiles (here, defined by `CHI_map`) as the first layer, you specify data and mapping inside of `geom_point()`.
```{r}
ggmap(CHI_map) +
  geom_point(data = carTheft,
             mapping = aes(x = Longitude,
                           y = Latitude),
             size = .25,
             alpha = .1)
```

Note `ggmap()` replaces `ggplot()`.

## Spatial density maps (extra material) {-}

Instead of relying on `geom_point()` and plotting the raw data, another approach is to create a heat map. This is done with a density estimator. Since the map has two dimensions and the density estimator requires a 'kernel' function the procedure is called a 2-D kernel density estimation (KDE). 

KDE will take all the data (i.e. reported vehicle thefts) and convert it into a smoothed plot showing geographic concentrations of crime. KDE is a type of data smoothing where inferences about the population are made based on a finite data sample. 

The core function in {ggplot2} to generate this kind of plot is `geom_density_2d()`.
```{r}
ggmap(CHI_map) +
  geom_density_2d(data = carTheft,
                  aes(x = Longitude,
                      y = Latitude))
```

By default, `geom_density_2d()` draws a contour plot with lines of constant value. That is, each line represents approximately the same frequency of crime along that specific line. Contour plots are often used in maps (known as topographic maps) to denote elevation.

Rather than drawing lines you fill in the graph by using the fill aesthetic to draw bands of crime density. To do that, you use the related function `stat_density_2d()`.
```{r}
ggmap(CHI_map) +
  stat_density_2d(data = carTheft,
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  geom = "polygon")
```

Note the two new arguments:

* `geom = "polygon"` - change the geometric object to be drawn from a `geom_density_2d()` geom to a polygon geom
* `fill = stat(level)` - the value for the fill aesthetic is the level calculated within `stat_density_2d()`, which you access using the `stat()` notation.

This is an improvement, but you can adjust some settings to make the graph visually more useful. Specifically,

* Increase the number of bins, or unique bands of color allowed on the graph
* Make the colors semi-transparent using alpha so you can still view the underlying map
* Change the color palette to better distinguish between high and low crime areas. 

Here you use `RColorBrewer::brewer.pal()` from the {RColorBrewer} package to create a custom color palette using reds and yellows.
```{r}
ggmap(CHI_map) +
  stat_density_2d(data = carTheft,
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  alpha = .2,
                  bins = 25,
                  geom = "polygon") +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(7, "YlOrRd"))
```

The downtown region has the highest rate of vehicle theft. Not surprising given its population density during the workday. There are also clusters of vehicle thefts on the south and west sides.