# Tuesday, October 4, 2022 {.unnumbered}

A former PhD student from this department, who I supervised, is looking for a masters-level geographer to assist with disease mapping and basic spatial analysis as applied to livestock disease.

To support non-spatial scientists (virologists, field epidemiologists) and post-docs (some with spatial analysis expertise) in the mapping and visualizing of disease occurrence data from across the US and encouraged to develop independent projects leading to publication. Flexible work location especially if working toward a PhD.

Here's the link: <https://www.zintellect.com/Opportunity/Details/USDA-ARS-2022-0343>

Today

-   Extended example: map tornado frequency
-   Geo-computation on simple feature data frames
-   Making raster maps
-   Spatial density maps

## Extended example: map tornado frequency {.unnumbered}

Let's look at another example. Here we have the tornado data from the Storm Prediction Center (SPC) as a shapefile in the directory `1950-2018-torn-aspath`.

Shapefiles are imported with the `sf::st_read()` function.

```{r}
Torn.sf <- sf::st_read(dsn = here::here("data", "1950-2020-torn-initpoint"), 
                       layer = "1950-2020-torn-initpoint")
```

The result is a simple feature data frame with 66244 features (observations) and 23 columns.

Each observation is a unique tornado. The coordinate reference system is geographic (longitude, latitude) with EPSG 4326.

You look inside the simple feature data frame with the `glimpse()` function from the {dplyr} package.

```{r}
Torn.sf |>
  dplyr::glimpse()
```

The first 22 columns are variables (attributes). The last column contains the geometry. Information in the `geometry` column is in well-known text (WKT) format.

Each tornado is a coded as a `LINESTRING` with a start and end location. This is where the `tmap::tm_shape()` function looks for the mapping information.

You map the tracks of all tornadoes since 2011. First you filter `Torn.sf` keeping only tornadoes occurring after 2010.

```{r}
Torn.sf <- Torn.sf |>
             dplyr::filter(yr >= 2011) 
```

Next get a boundary map of the lower 48 states using the `USAboundaries::us_states()` function and remove rows corresponding to Hawaii, Alaska, and Puerto Rico.

```{r}
USA_48.sf <- USAboundaries::us_states() |>
   dplyr::filter(!state_name %in% c("Hawaii", "Alaska", "Puerto Rico"))
```

The objects `Torn.sf` and `USA_48.sf` are both simple feature data frames so you map variables in them as layers with successive calls to the `tmap::tm_shape()` function. For example, you start with a boundary map of the lower 48 states with `tmap::tm_polygons()` and then overlay the tornadoes with `tmap::tm_shape()` and `tmap::tm_lines()`.

```{r}
tmap::tm_shape(shp = USA_48.sf) +
  tmap::tm_polygons() +
tmap::tm_shape(shp = Torn.sf) +
    tmap::tm_dots(col = "red")
```

Let's try something a bit more complicated. Suppose you want to map the number of tornadoes originating in each state. You first filter `Torn.sf` to include only tornadoes occurring in the lower 48 states, you then group by state and summarize with the `n()` function that returns the number of cases by the grouping variable (`st`). You rename the variable `st` to match the variable `state_abbr` variable in the `USA_48.sf`. Finally you remove the `sfc` with the `sf::st_drop_geometry()` function.

```{r}
Torn_Counts.df <- Torn.sf |>
  dplyr::filter(!st %in% c("PR", "HI" , "AK", "DC", "VI")) |>
  dplyr::group_by(st) |>
  dplyr::summarize(nT = dplyr::n()) |>
  dplyr::rename(state_abbr = st) |>
  sf::st_drop_geometry()

Torn_Counts.df |>
  dplyr::glimpse()
```

The resulting data frame contains the state abbreviation and the corresponding number of tornadoes. There were 609 tornadoes in Alabama since 2011, 326 in Arkansas, etc.

Then you join the counts data frame with the map boundary simple feature data frame using the `dplyr::left_join()` function. Note the `y =` argument to the function only works with data frames so that is why you dropped the geometry with `sf::st_drop_geometry()` above.

```{r}
Count_Map.sf <- USA_48.sf |>
  dplyr::left_join(Torn_Counts.df,
                   by = "state_abbr") |>
  dplyr::select(nT)

Count_Map.sf |>
  dplyr::glimpse()
```

Next you make a thematic map of the counts.

```{r}
tmap::tm_shape(shp = Count_Map.sf) +
  tmap::tm_polygons(col = "nT", 
                    title = "Tornado Counts",
                    palette = "Reds")
```

You can then improve the defaults with additional layers including text, compass, and scale bar.

```{r}
tmap::tm_shape(shp = Count_Map.sf) +
  tmap::tm_polygons(col = "nT", 
                    border.col = "gray70",
                    title = "Tornado Counts",
                    palette = "Reds") +
  tmap::tm_text("nT", size = 1) +
  tmap::tm_compass() + 
  tmap::tm_scale_bar(lwd = .5)
```

Summary: The format of the {tmap} objects (meoms) are like those of the {ggplot2} geometric objects (geoms) making it easy to get to a publication-quality map. Fine details are worked out in production.

[More information?](https://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.html)

## Geo-computation on simple feature data frames {.unnumbered}

Spatial data analysis often requires calculations on the geometry. Two of the most common are computing centroids (geographic centers) and buffers.

Geometry calculations should be done on projected coordinates. To see what CRS the simple feature data frame has use `sf::st_crs()`.

```{r}
sf::st_crs(USA_48.sf)
```

Note the length unit (`LENGTHUNIT[]`) is meter.

Here transform the CRS of the `USA_48.sf` simple feature data frame to a U.S. National Atlas equal area (EPSG: 2163) and then check it.

```{r}
USA_48.sf <- USA_48.sf |>
  sf::st_transform(crs = 2163)

sf::st_crs(USA_48.sf)
```

The centroid calculation locates the center of geographic objects representing the center of mass for the spatial object (think of balancing a plate on your finger).

You calculate the geographic centroid of each of the lower 48 states with the `st_centroid()` function.

```{r}
geo_centroid.sf <- USA_48.sf |>
  sf::st_centroid()
```

The result is a simple feature data frame where the geometry is a single point for each state. You keep track of the fact that this is a simple feature data frame by using an object name that includes appends with `.sf`.

The warning tells you that the attributes in the new simple feature data frame may not make sense with the new geometry.

For example, compare the first two rows of the two simple feature data frames.

```{r}
head(geo_centroid.sf, n = 2)
head(USA_48.sf, n = 2)
```

The land area (`aland`) makes sense when the geometry is `MULTIPOLYGON` it is less congruent when the geometry is `POINT`.

You map the points using the `tm_dots()` function after first mapping the state borders.

```{r}
tmap::tm_shape(shp = USA_48.sf) +
  tmap::tm_borders(col = "gray70") +
tmap::tm_shape(shp = geo_centroid.sf) +
  tmap::tm_dots(size = 1,
                col = "black")
```

Buffers are polygons representing the area within a given distance of a geometric feature. Regardless of whether the feature is a point, a line, or a polygon.

The function `sf::st_buffer()` computes the buffer and you set the distance with the `dist =` argument. Here you create a new simple feature data frame with only the state of Florida.

You then compute a 50 km (50,000 meters) buffer and save the resulting polygon

```{r}
FL.sf <- USA_48.sf |>
   dplyr::filter(state_abbr == "FL")

FL_buffer.sf <- FL.sf |>
   sf::st_buffer(dist = 50000)
```

Create a map containing the state border, the 50 km buffer, and the centroid. Include a compass arrow and a scale bar.

```{r}
tmap::tm_shape(FL_buffer.sf) +
  tmap::tm_borders(col = "gray70") +
tmap::tm_shape(FL.sf) +
  tmap::tm_borders() +
tmap::tm_shape(geo_centroid.sf) +
  tmap::tm_dots(size = 2) +
tmap::tm_compass(position = c("left", "bottom")) + 
tmap::tm_scale_bar(text.size = 1, 
                   position = c("left", "bottom"))
```

The result is a map that could serve as a map of your study area (usually Figure 1 in scientific report).

## Making raster maps {.unnumbered}

The package {ggmap} retrieves raster map tiles (groups of pixels) from services like Google Maps and plots them using the {ggplot2} grammar.

Map tiles are rasters as static image files generated by the mapping service. You do not need data files containing information on things like scale, projection, boundaries, etc. because that information is created by the map tile.

This limits the ability to redraw or change the appearance of the map but it allows for easy data overlays onto the map.

You get map tiles with the `ggmap::get_map()` function from the {ggmap} package. You specify the bounding box (or the center and zoom). The bounding box requires the left-bottom and right-top corners of the region specified as longitude and latitude in decimal degrees.

For instance, to obtain a map of Tallahassee from the stamen mapping service you first set the bounding box (left-bottom corner as -84.41, 30.37 and right-top corner as -84.19, 30.55) then use the `ggmap::get_stamenmap()` function with a zoom level of 12.

```{r, message=FALSE}
library(ggmap)

TLH_bb <- c(left = -84.41,
            bottom = 30.37,
            right = -84.19,
            top = 30.55)

TLH_map <- ggmap::get_stamenmap(bbox = TLH_bb,
                                zoom = 12)
TLH_map
```

The saved object (`TLH_map`) is a raster map specified by the class `ggmap`.

To view the map, use `ggmap()` function.

```{r}
ggmap::ggmap(TLH_map)
```

The `zoom =` argument in the `ggmap::get_stamenmap()` function controls the level of detail. The larger the number, the greater the detail.

Trial and error helps you decide on the appropriate level of detail depending on the data you need to visualize. Use [boxfinder](bboxfinder.com) to determine the exact longitude/latitude coordinates for the bounding box you wish to obtain.

Or you can use the `tmaptools::geocode_OSM()` function from the {tmaptools} package. You first specify a location then get a geo-coded coordinate.

```{r}
FSU.list <- tmaptools::geocode_OSM("Florida State University")
FSU.list
```

The object `FSU.list` is a list containing three elements `query`, `coords` and `bbox`. You are interested in the `bbox` element so you save that as vector that you assign `FSU_bb` and rename the elements to left, bottom, right, and top.

```{r}
FSU_bb <- FSU.list$bbox
names(FSU_bb) <- c("left", "bottom", 
                   "right", "top")
FSU_bb
```

You then get the map tiles corresponding to the bounding box from the stamen map service with a zoom of 16 and create the map.

```{r, message=FALSE}
FSU_map <- ggmap::get_stamenmap(bbox = FSU_bb, 
                                zoom = 16)
ggmap::ggmap(FSU_map)
```

Add data to the raster map. Let's consider a map of Chicago.

```{r, message=FALSE}
CHI_bb <- c(left = -87.936287,
            bottom = 41.679835,
            right = -87.447052,
            top = 42.000835)

CHI_map <- ggmap::get_stamenmap(bbox = CHI_bb,
                                zoom = 11,
                                messaging = FALSE)
ggmap::ggmap(CHI_map)
```

The city of Chicago has a data portal publishing a large volume of public records. Here you look at crime data from 2017. The file `car_thefts.csv` is a spreadsheet obtained from that portal with a list of car thefts.

You read these data using the `readr::read_csv()` function.

```{r}
carTheft <- readr::read_csv(file = here::here("data", "car_thefts.csv"))
head(carTheft)
```

Each row of the data frame is a single report of a vehicle theft. Location is encoded in several ways, though most importantly for your purpose the longitude and latitude of the theft is encoded in the `Longitude` and `Latitude` columns, respectively.

You use the `geom_point()` function to map the location of every theft. Because `ggmap()` uses the map tiles (here, defined by `CHI_map`) as the first layer, you specify data and mapping inside of `geom_point()`.

```{r}
library(ggplot2)

ggmap::ggmap(CHI_map) +
  geom_point(data = carTheft,
             mapping = aes(x = Longitude,
                           y = Latitude),
             size = .25,
             alpha = .1)
```

Note the function `ggmap::ggmap()` replaces the function `ggplot()`.

## Spatial density maps {.unnumbered}

Instead of relying on `geom_point()` and plotting the raw data, another approach is to create a heat map. This is done with a density estimator. Since the map has two dimensions and the density estimator requires a 'kernel' function the procedure is called a 2-D kernel density estimation (KDE).

KDE will take all the data (i.e. reported vehicle thefts) and convert it into a smoothed plot showing geographic concentrations of crime. KDE is a type of data smoothing where inferences about the population are made based on a finite data sample.

The core function in {ggplot2} to generate this kind of plot is `geom_density_2d()`.

```{r}
ggmap::ggmap(CHI_map) +
  geom_density_2d(data = carTheft,
                  aes(x = Longitude,
                      y = Latitude))
```

By default, `geom_density_2d()` draws a contour plot with lines of constant value. That is, each line represents approximately the same frequency of crime along that specific line. Contour plots are often used in maps (known as topographic maps) to denote elevation.

Rather than drawing lines you fill in the graph by using the fill aesthetic to draw bands of crime density. To do that, you use the related function `stat_density_2d()`.

```{r}
ggmap::ggmap(CHI_map) +
  stat_density_2d(data = carTheft,
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  geom = "polygon")
```

Note the two new arguments:

-   `geom = "polygon"` - change the geometric object to be drawn from a `geom_density_2d()` geom to a polygon geom
-   `fill = stat(level)` - the value for the fill aesthetic is the level calculated within `stat_density_2d()`, which you access using the `stat()` notation.

This is an improvement, but you can adjust some settings to make the graph visually more useful. Specifically,

-   Increase the number of bins, or unique bands of color allowed on the graph
-   Make the colors semi-transparent using alpha so you can still view the underlying map
-   Change the color palette to better distinguish between high and low crime areas.

Here you use `RColorBrewer::brewer.pal()` from the {RColorBrewer} package to create a custom color palette using reds and yellows.

```{r}
ggmap::ggmap(CHI_map) +
  stat_density_2d(data = carTheft,
                  aes(x = Longitude,
                      y = Latitude,
                      fill = stat(level)),
                  alpha = .2,
                  bins = 25,
                  geom = "polygon") +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(7, "YlOrRd"))
```

The downtown region has the highest rate of vehicle theft. Not surprising given its population density during the workday. There are also clusters of vehicle thefts on the south and west sides of the city.

## Assignment #3 {.unnumbered}
