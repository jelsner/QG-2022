---
title: "GEO5156: Quantitative Geography"
subtitle: "Fall 2022"
author: "James B. Elsner"
date: "Date compiled: `r Sys.Date()`"
bibliography: ["References.bib"]
biblio-style: apalike
link-citations: yes
github-repo: jelsner/QG-2022
site: "bookdown::bookdown_site"
documentclass: book
editor_options: 
  chunk_output_type: console
---
---
title: "GEO5156: Quantitative Geography"
subtitle: "Fall 2022"
author: "James B. Elsner"
date: "Date compiled: `r Sys.Date()`"
bibliography: ["References.bib"]
biblio-style: apalike
link-citations: yes
github-repo: jelsner/QG-2022
site: "bookdown::bookdown_site"
documentclass: book
editor_options: 
  chunk_output_type: console
---

<!--chapter:end:index.Rmd-->


# Syllabus {.unnumbered}

Placeholder


## GEO5165C: Quantitative Geography {.unnumbered}
## Contact information {.unnumbered}
## Course description and expected learning outcomes {.unnumbered}
## Grades and ethics {.unnumbered}
## Schedule (subject to change with notice) {.unnumbered}
## Deeper dives {.unnumbered}

<!--chapter:end:00-Syllabus.Rmd-->


# Tuesday, August 23, 2022 {-}

Placeholder


## What is this course? {-}
## Where are the materials for this course? {-}
## Get the syllabus {-}
## Getting setup {-}
## Getting to know RStudio's integrated development environment (IDE) {-}

<!--chapter:end:01-Lesson.Rmd-->


# Thursday, August 25, 2022 {.unnumbered}

Placeholder


## Data science {.unnumbered}
## Structure of markdown files {.unnumbered}
## How to make a plot {.unnumbered}
## Getting started using R {.unnumbered}

<!--chapter:end:02-Lesson.Rmd-->


# Tuesday, August 30, 2022 {.unnumbered}

Placeholder


## Graphing examples {.unnumbered}
## Introduction to working with base R {.unnumbered}
## Data as vectors {.unnumbered}

<!--chapter:end:03-Lesson.Rmd-->


# Thursday, September 1, 2022 {.unnumbered}

Placeholder


## Statistical summaries of data {.unnumbered}
## Structured data {.unnumbered}
## Tables {.unnumbered}
## Assignment #1 {-}

<!--chapter:end:04-Lesson.Rmd-->


# Tuesday, September 6, 2022 {.unnumbered}

Placeholder


## Getting data into R {.unnumbered}
## Data frames {.unnumbered}
## Piping your commands {-}

<!--chapter:end:05-Lesson.Rmd-->

# Thursday, September 8, 2022 {.unnumbered}

Today

-   Data transformation with {dplyr}
-   From data import to final plot

## Data transformation with {dplyr} {.unnumbered}

You extract information from data frames (data munging) with {dplyr} functions. The functions work on data frames but they work better if the data frame is a *tibble*. Tibbles are data frames that make things a little easier.

R is an old language, and some things that were useful 10 or 20 years ago now get in the way. To make a data frame a tibble (tabular data frame) type

```{r}
airquality <- dplyr::as_tibble(airquality)
class(airquality)
```

Or using the piping operator.

```{r}
airquality <- airquality |>
  dplyr::as_tibble()
class(airquality)
```

Click on `airquality` in the environment. It is a data frame.

Selecting and filtering

The function `select()` chooses variables by name to create a data frame with fewer columns. For example, choose the month, day, and temperature columns from the `airquality` data frame.

```{r}
airquality |>
  dplyr::select(Month, Day, Temp)
```

Suppose you want a new data frame with only the temperature and ozone concentrations.

```{r}
df <- airquality |>
        dplyr::select(Temp, Ozone)
df
```

You include an assignment operator (`<-`) and an object name (here `df`).

Note: The result of applying most {dplyr} verbs is a data frame. The take only data frames and return only data frames.

The function `filter()` chooses observations based on specific values.

![filter](https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/rstats-artwork/dplyr_filter.jpg)

Suppose you want only the observations where the temperature is at or above 80F.

```{r}
airquality |>
  dplyr::filter(Temp >= 80)
```

The result is a data frame with the same 6 columns but now only 73 observations. Each of the observations has a temperature of at least 80F.

Suppose you want a new data frame keeping only observations where temperature is at least 80F AND winds less than 5 mph.

```{r}
df <- airquality |> 
  dplyr::filter(Temp >= 80 & Wind < 5)
df
```

Example: Let's return to the penguins data set. The data set is located on the web, and you import it as a data frame using the `readr::read_csv()` function.

```{r}
loc <- "https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv"
penguins <- readr::read_csv(loc)
penguins
```

To keep only the penguins labeled in the column `sex` as `female` type

```{r}
penguins |> 
  dplyr::filter(sex == "female")
```

To filter rows keeping only species that are not Adalie penguins.

```{r}
penguins |> 
  dplyr::filter(species != "Adelie")
```

When the column of interest is a numerical, you can filter rows by using greater than condition. For example, to create a data frame containing the heaviest penguins you filter keeping only rows with body mass greater than 6000 g.

```{r}
penguins |> 
  dplyr::filter(body_mass_g > 6000)
```

You can also filter rows of a data frame with less than condition. For example, to create a data frame containing only penguins with short flippers you filter keeping only rows with flipper length less than 175 mm.

```{r}
penguins |> 
  dplyr::filter(flipper_length_mm < 175)
```

You can also specify more than one conditions. For example to create a data frame with female penguins that have larger flippers you filter keeping only rows with flipper length greater than 220 mm and with sex equal to female.

```{r}
penguins |> 
  dplyr::filter(flipper_length_mm > 220 & 
                sex == "female")
```

You can also filter a data frame for rows satisfying one of the two conditions using OR. For example to create a data frame with penguins have large flippers or short bills you filter keeping rows with flipper length of at least 220 mm or with bill depth less than 10 mm.

```{r}
penguins |> 
  dplyr::filter(flipper_length_mm > 220 | 
                bill_depth_mm < 10)
```

Often you want to remove rows if one of the columns has a missing value. With `is.na()` on the column of interest, you can filter rows based on whether or not a column value is missing.

The `is.na()` function returns a vector of TRUEs and FALSEs

```{r}
airquality$Ozone |>
  is.na()
```

The first four rows of the vector `Ozone` in the `airquality` data frame are not missing so the function `is.na()` returns four `FALSE`s.

When you combine that with the `filter()` function you get a data frame containing all the rows where `is.na()` returns a `TRUE`. For example, create a data frame containing rows where the bill length value is missing.

```{r}
penguins |> 
  dplyr::filter(is.na(bill_length_mm))
```

Usually you will want to do the reverse of this. That is keep all the rows where the column value is not missing. In this case use negation symbol `!` to reverse the selection. In this example, filter rows with no missing values for `sex` column.

```{r}
penguins |> 
  dplyr::filter(!is.na(sex))
```

Note that this filtering will keep rows with other column values that are missing values but there will be no penguins where the `sex` value is `NA`.

Stringing functions together

The function `arrange()` orders the rows by values given in a particular column.

```{r}
airquality |>
  dplyr::arrange(Solar.R)
```

The ordering is from lowest value to highest value. Here the first 10 rows. Note `Month` and `Day` are no longer chronological.

Repeat but order by the value of air temperature.

```{r}
airquality |>
  dplyr::arrange(Temp)
```

Importantly you can string the functions together. For example select the variables radiation, wind, and temperature then filter by temperatures above 90F and arrange from coolest to warmest by temperature.

```{r}
airquality |>
  dplyr::select(Solar.R, Wind, Temp) |>
  dplyr::filter(Temp > 90) |>
  dplyr::arrange(Temp)
```

The result is a data frame with three columns and 14 rows arranged by increasing temperatures above 90F.

The `mutate()` function adds new columns to the data frame.

![mutate](figures/dplyr_mutate.png)

For example, create a new column called `TempC` as the temperature in degrees Celsius. Also create a column called `WindMS` as the wind speed in meters per second.

```{r}
airquality |>
  dplyr::mutate(TempC = (Temp - 32) * 5/9,
                WindMS = Wind * .44704) 
```

The resulting data frame has 8 columns (two new ones) labeled `TempC` and `WindMS`.

On days when the temperature is colder than 60 F, add a column giving the apparent temperature based on the cooling effect of the wind (wind chill) and then arrange from coldest to warmest apparent temperature.

```{r}
airquality |>
  dplyr::filter(Temp < 60) |>
  dplyr::mutate(TempAp = 35.74 + 
                  .6215 * Temp - 
                  35.75 * Wind^.16 + 
                  .4275 * Temp * Wind^.16) |>
  dplyr::arrange(TempAp)
```

The `summarize()` function reduces (flattens) the data frame based on a function that computes a statistic. For example, to compute the average wind speed during July type

```{r}
airquality |>
  dplyr::filter(Month == 7) |>
  dplyr::summarize(Wavg = mean(Wind))

airquality |>
  dplyr::filter(Month == 6) |>
  dplyr::summarize(Tavg = mean(Temp))
```

R functions that compute statistics on vectors include `sum()`, `sd()`, `min()`, `max()`, `var()`, `range()`, `median()`. Others from the {dplyr} package include

|      Summary function | Description               |
|----------------------:|:--------------------------|
|          `dplyr::n()` | Length of the column      |
|      `dplyr::first()` | First value of the column |
|       `dplyr::last()` | Last value of the column  |
| `dplyr::n_distinct()` | Number of distinct values |

Find the maximum and median wind speed and maximum ozone concentration values during the month of May. Also determine the number of observations during May.

```{r}
airquality |>
  dplyr::filter(Month == 5) |>
  dplyr::summarize(Wmax = max(Wind), 
                   Wmed = median(Wind), 
                   OzoneMax = max(Ozone), 
                   NumDays = dplyr::n())
```

Why do you get an `NA` for `OzoneMax`?

Fix this by including the argument `na.rm = TRUE` inside the `max()` function.

```{r}
airquality |>
  dplyr::filter(Month == 5) |>
  dplyr::summarize(Wmax = max(Wind),
                   Wmed = median(Wind),
                   OzoneMax = max(Ozone, na.rm = TRUE),
                   NumDays = dplyr::n())
```

To summarize separately for each month use the `group_by()` function. You split the data frame by some variable (e.g., `Month`), apply a function to the individual data frames, and then combine the output.

Find the highest ozone concentration by month. Include the number of observations (days) in the month.

```{r}
airquality |>
  dplyr::group_by(Month) |>
  dplyr::summarize(OzoneMax =  max(Ozone, na.rm = TRUE),
                   NumDays = dplyr::n())
```

Find the average ozone concentration when temperatures are above and below 70 F. Include the number of observations (days) in the two groups.

```{r}
airquality |>
  dplyr::group_by(Temp >= 70) |>
  dplyr::summarize(OzoneAvg =  mean(Ozone, na.rm = TRUE),
                   NumDays = dplyr::n())
```

On average ozone concentration is higher on warm days (Temp \>= 70 F) days. Said another way; mean ozone concentration statistically depends on temperature.

The mean is a model for the data. The statistical dependency of the mean implies that a model for ozone concentration will likely be improved by including temperature as an explanatory variable.

To summarize, the important verbs are

|                 Verb | Description                                                                    |
|--------------------------------------:|:--------------------------------|
|    `dplyr::select()` | selects columns; pick variables by their names                                 |
|    `dplyr::filter()` | filters rows; pick observations by their values                                |
|    `dplyr::mutate()` | creates new columns; create new variables with functions of existing variables |
| `dplyr::summarize()` | summarizes values; collapse many values down to a single summary               |
|  `dplyr::group_by()` | allows operations to be grouped                                                |

The syntax of the verb functions are all the same:

The first argument is a data frame. This argument is implicit when using the `|>` operator. The subsequent arguments describe what to do with the data frame. You refer to columns in the data frame directly (without using `$`). The result is a new data frame.

These properties make it easy to chain together many simple lines of code to do something complex.

The five functions form the basis of a grammar for data. At the most basic level, you can only alter a data frame by (1) reorder the rows (`arrange()`), (2 & 3) pick observations and variables of interest (`filter()` and `select()`), (4) add new variables that are functions of existing variables (`mutate()`), or (5) collapse many values to a summary (`summarise()`).

Example: Let's consider another set of data. Daily high and low temperatures and precipitation in Tallahassee. The file (`TLH_SOD1892.csv`) is available in this project in the folder `data`.

Import the data as a data frame.

```{r}
TLH.df <- readr::read_csv(file = here::here("data", "TLH_SOD1892.csv"))
```

The data frame contains daily high (`TMAX`) and low (`TMIN`) temperatures and total precipitation (`PRCP`) from two stations: Airport with `STATION` identification USW00093805 and downtown with `STATION` identification USC00088754.

Use the `select()` function to create a new data frame with only `STATION`, `DATE`, `PRCP`, `TMAX` and `TMIN`.

```{r}
( TLH.df <- TLH.df |>
  dplyr::select(STATION, DATE, PRCP, TMAX, TMIN) )
```

Note that you've recycled the name of the data frame. You started with `TLH.df` containing all the columns and you ended with `TLH.df` with only the columns selected.

Then use the `filter()` function to keep only days at or above 90F. Similarly you recycle the name of the data frame. Use the `glimpse()` function to take a look at the resulting data frame.

```{r}
TLH.df <- TLH.df |>
  dplyr::filter(TMAX >= 90) |>
  dplyr::glimpse()
```

Note that the `DATE` column is a vector of dates having class `date`. If this is a character string you can convert it to a `date` with the `as.Date()` function.

Functions from the {lubridate} package are used to extract information from `date`s. Here you add columns labeled `Year`, `Month`, and `Day` using the functions `year()`, `month()`, `day()` and `weekdays()`.

```{r}
( TLH.df <- TLH.df |>
  dplyr::mutate(Year = lubridate::year(DATE),
                Month = lubridate::month(DATE),
                Day = lubridate::day(DATE),
                DoW = lubridate::weekdays(DATE)) )
```

Next you keep only the temperature record from the airport. You use the `filter()` function on the column labeled `STATION`.

```{r}
TLH.df <- TLH.df |>
  dplyr::filter(STATION == "USW00093805")
```

Now what if you want to know how many hot days (90F or higher) by year? You use the `dplyr::group_by()` function and count using the `dplyr::n()` function.

```{r}
( TLH90.df <- TLH.df |>
  dplyr::group_by(Year) |>
  dplyr::summarize(nHotDays = dplyr::n()) )
```

Note that the `dplyr::group_by()` function results in a data frame with the first column the variable used inside the function. In this case it is `Year`. The next columns are defined by what is in the `dplyr::summarize()` function.

Repeat but this time group by `Month`.

```{r}
TLH.df |>
  dplyr::group_by(Month) |>
  dplyr::summarize(nHotDays = dplyr::n())
```

As expected the number of 90F+ days is highest in July and August. Note that we've had 90F+ days in October here in Tallahassee.

Would you expect there to be more hot days on the weekend? How would you check this?

```{r}
TLH.df |>
  dplyr::group_by(Year, DoW) |>
  dplyr::summarize(nHotDays = dplyr::n())
```

You can group by more than one variable. For example, add the variable `Year` to the `group_by()` function above.

Recall that you can also `arrange()` the data frame ordered according to the values in a particular column.

```{r}
TLH90.df |>
  dplyr::arrange(desc(nHotDays))
```

## From data import to final plot {.unnumbered}

Let's put together a piece of original reproducible research. You know how to import a data, you know how to manipulate a data frame to compute something of interest, and you know how to make a graph.

Let's do this for the number of hot days in Tallahassee. Let's say you want a plot of the annual number of hot days since 1950. Let's define a hot day as one where the high temperature is at least 90F.

```{r}
library(ggplot2)

readr::read_csv(file = "data/TLH_SOD1892.csv") |>
  dplyr::filter(STATION == "USW00093805",
                TMAX >= 90) |>
  dplyr::mutate(Year = year(DATE)) |>
  dplyr::filter(Year >= 1950) |>
  dplyr::group_by(Year) |>
  dplyr::summarize(nHotDays = dplyr::n()) |>
ggplot(aes(x = Year, y = nHotDays)) +
  geom_point() +
  geom_smooth() +
  scale_y_continuous(limits = c(0, NA)) +
  ylab("Number of Days") +
  ggtitle("Number of Hot Days in Tallahassee Since 1950",
          subtitle = "High Temperature >= 90F") +
  theme_minimal()
```

You go from data in a file to a plot of interest with a set of functions that are logically ordered and easy to read.

What would you change to make a similar plot for the number of hot nights (say where the minimum temperature fails to drop below 74)?

```{r}
readr::read_csv(file = "data/TLH_SOD1892.csv") |>
  dplyr::filter(STATION == "USW00093805",
                TMIN >= 74) |>
  dplyr::mutate(Year = year(DATE)) |>
  dplyr::filter(Year >= 1950) |>
  dplyr::group_by(Year) |>
  dplyr::summarize(nHotNights = dplyr::n()) |>
ggplot(aes(x = Year, y = nHotNights)) +
  geom_point() +
  geom_smooth() +
  scale_y_continuous(limits = c(0, NA)) +
  ylab("Number of Nights") +
  ggtitle("Number of Hot Nights in Tallahassee Since 1950",
          subtitle = "Low Temperature >= 74F") +
  theme_minimal()
```

Make a similar plot showing the total precipitation by year.

```{r}
readr::read_csv(file = "data/TLH_SOD1892.csv") |>
  dplyr::filter(STATION == "USW00093805") |>
  dplyr::mutate(Year = year(DATE)) |>
  dplyr::filter(Year >= 1950) |>
  dplyr::group_by(Year) |>
  dplyr::summarize(TotalPrecip = sum(PRCP)) |>
ggplot(aes(x = Year, y = TotalPrecip)) +
  geom_point() +
  geom_smooth() +
  scale_y_continuous(limits = c(0, NA)) +
  ylab("Total Precipitation by Year") +
  theme_minimal()
```

Example: Food consumption and CO2 emissions

Source: <https://www.nu3.de/blogs/nutrition/food-carbon-footprint-index-2018>

```{r}
fc.df <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-18/food_consumption.csv')

head(fc.df)
```

Consumption is kg/person/year and CO2 emission is kg CO2/person/year. I note that emission in the column name is mispelled.

(1) How many different countries are in the data frame?

```{r}
fc.df |>
  dplyr::distinct(country) |>
  nrow()
```

(2) Arrange the countries from most pork consumption (per person) to the least pork consumption.

```{r}
fc.df |>
  dplyr::filter(food_category == "Pork") |>
  dplyr::select(country, consumption) |>
  dplyr::arrange(desc(consumption))
```

(3) Arrange the countries from the largest carbon footprint with respect to eating habits to the smallest carbon footprint.

```{r}
fc.df |>
  dplyr::rename(co2_emission = co2_emmission) |>
  dplyr::group_by(country) |>
  dplyr::summarize(totalEmission = sum(co2_emission)) |>
  dplyr::arrange(desc(totalEmission))
```

To summarize: Data munging is a big part of data science. Data science is an iterative cycle:

1.  Generate questions of interest that can be answered with your data.
2.  Search for answers by transforming, visualizing, and modeling the data.
3.  Use what you learn to refine your questions and/or ask new ones.

You use questions as tools to guide the investigation. When you ask a question, the question focuses your attention on a specific part of the data and helps you decide what to do.

For additional practice check out <http://r4ds.had.co.nz/index.html> Data Transformation

Cheat sheets <http://rstudio.com/resources/cheatsheets>

<!--chapter:end:06-Lesson.Rmd-->


# Thursday, September 13, 2022 {.unnumbered}

Placeholder


## Data visualization {.unnumbered}

<!--chapter:end:07-Lesson.Rmd-->


# Tuesday, September 20, 2022 {-}

Placeholder


## Data visualization continued {-}

<!--chapter:end:09-Lesson.Rmd-->


# Thursday, September 22, 2022 {-}

Placeholder


## Simple feature data frames {-}
## Making a boundary map {-}
## Inset maps {-}
## Map projections {-}
## Bivariate maps (extra material) {-}

<!--chapter:end:10-Lesson.Rmd-->


# Tuesday, September 27, 2022 {-}

Placeholder


## Making maps using functions from the {tmap} package {-}
## Calculations using the geometry simple feature column {-}
## Making raster maps {-}
## Spatial density maps (extra material) {-}

<!--chapter:end:11-Lesson.Rmd-->


# Thursday, September 29, 2022 {-}

Placeholder


## One-sample test of the population mean {-}
## About p-values {-}
## Graphical inference {-}
## Two-sample test for the difference in population means {-}
## Test of equal variance {-}
## Wilcoxon (Mann-Whitney U) non-parameteric test of difference in means {-}

<!--chapter:end:12-Lesson.Rmd-->


# Tuesday, October 4, 2022 {-}

Placeholder


## Paired observations {-}
## Chi-squared test for independence {-}

<!--chapter:end:13-Lesson.Rmd-->


# Thursday, October 6, 2022 {-}

Placeholder


## Bayesian data analysis {-}

<!--chapter:end:14-Lesson.Rmd-->


# Tuesday, October 11, 2022 {-}

Placeholder


## More examples of Bayesian data analyses {-}

<!--chapter:end:15-Lesson.Rmd-->


# Thursday, October 13, 2022 {-}

Placeholder


## Linear regression: A t test by another name {-}
## Motivation for the regression model {-}
## Making predictions with the regression model {-}
## Uncertainty about the regression model coefficients {-}
## Bootstrapping the uncertainty {-}

<!--chapter:end:16-Lesson.Rmd-->


# Tuesday, October 18, 2022 {-}

Placeholder


## Uncertainty about a particular predicted value {-}
## Model Adequacy {-}
## Transforming the response variable {-}

<!--chapter:end:17-Lesson.Rmd-->


# Thursday, October 20, 2022 {-}

Placeholder


## More regression examples {-}
## Outliers {-}
## Simpson's paradox {-}

<!--chapter:end:18-Lesson.Rmd-->


# Tuesday, October 25, 2022 {-}

Placeholder


## A regression plane {-}
## Fitting a multiple variable regression model {-}
## Should you remove a variable from the model? {-}
## Checking on the model assumptions {-}
## Using the model to make predictions {-}
## Collinearity {-}
## Interactions {-}

<!--chapter:end:19-Lesson.Rmd-->


# Thursday, October 27, 2022 {-}

Placeholder


## Removing variables from a regression model {-}
## The stepwise selection procedure {-}
## Transforming a response variable {-}
## Regression trees {-}

<!--chapter:end:20-Lesson.Rmd-->


# Tuesday, November 1, 2022 {-}

Placeholder


## Predictive uncertainty with regression trees {-}
## The random forest algorithm {-}
## Cross validation {-}
## Classification trees {-}

<!--chapter:end:21-Lesson.Rmd-->


# Thursday, November 3, 2022 {-}

Placeholder


## Binary outcomes and probabilities {-}
## Logistic regression {-}

<!--chapter:end:22-Lesson.Rmd-->


# Tuesday, November 8, 2022 {-}

Placeholder


## Quantifying autocorrelation in spatial data {-}
## Spatial data as polygon areas {-}
## Nearest neighbors {-}
## Spatial weights {-}
## Moran's I {-}
## Spatial lag variable {-}

<!--chapter:end:23-Lesson.Rmd-->


# Thursday, November 10, 2022 {-}

Placeholder


## Statistical significance of spatial autocorrelation {-}
## A Monte Carlo approach to inference about spatial autocorrelation {-}
## Spatial autocorrelation in model residuals {-}

<!--chapter:end:24-Lesson.Rmd-->


# Tuesday, November 15, 2022 {-}

Placeholder


## Bi-variate spatial autocorrelation {-}
## Local autocorrelation {-}
## Local regression {-}
## Spatial weights {-}

<!--chapter:end:25-Lesson.Rmd-->


# Thursday, November 17, 2022 {-}

Placeholder


## Geographic regression {-}

<!--chapter:end:26-Lesson.Rmd-->

